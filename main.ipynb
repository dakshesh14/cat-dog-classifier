{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset\n",
    "We will get our dataset from kaggle, for this you will have to add kaggle.json file in the `/content` directory. You can find the json [here](https://www.kaggle.com/settings/account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d salader/dogs-vs-cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un-zipping the dataset\n",
    "Since the dataset downloaded from kaggle is in zip file, we will have to un-zip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
    "zip_ref.extractall('/content')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential, regularizers\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generators\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = '/content/train',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=32,\n",
    "    image_size=(256,256)\n",
    ")\n",
    "\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = '/content/test',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=32,\n",
    "    image_size=(256,256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(image, label):\n",
    "  image = tf.cast(image / 255. , tf.float32)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(normalization)\n",
    "val_ds = val_ds.map(normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(256,256,3)),\n",
    "    MaxPooling2D(pool_size=(3,2), strides=2, padding='valid'),\n",
    "\n",
    "    Conv2D(\n",
    "        64,\n",
    "        kernel_size=(3,3),\n",
    "        padding='valid',\n",
    "        activation='relu',\n",
    "    ),\n",
    "    MaxPooling2D(pool_size=(3,2), strides=2, padding='valid'),\n",
    "\n",
    "    Conv2D(128, kernel_size=(3,3), padding='valid', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3,2), strides=2, padding='valid'),\n",
    "\n",
    "    Conv2D(\n",
    "        256,\n",
    "        kernel_size=(3,3),\n",
    "        padding='valid',\n",
    "        activation='relu',\n",
    "      ),\n",
    "    MaxPooling2D(pool_size=(3,2), strides=2, padding='valid'),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the model \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],color='red',label='train')\n",
    "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://i.natgeofe.com/n/548467d8-c5f1-4551-9f58-6817a8d2c45e/NationalGeographic_2572187_square.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_image_test = cv2.imread('/content/NationalGeographic_2572187_square.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cat_image_test) # for showing cute lil cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_image_test = cv2.resize(cat_image_test,(256,256))\n",
    "cat_image_test = cat_image_test.reshape((1,256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(cat_image_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
